<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
   "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
<title>CSCI 544: Homework 2</title>
</head>

<body>

<h1>CSCI 544&nbsp;&mdash; Applied Natural Language Processing</h1>

<hr>
<h2>Homework 2</h2>
<h2>Due: February 4, 2016, at 23:59 Pacific Time (11:59 PM)</h2>
<p>Assignments turned in after the deadline but before February&nbsp;7
are subject to a 30% grade penalty. Students who registered for the
class after January&nbsp;25 are not subject to the penalty. 

<p><span style="font-weight:bold ; color:red">Deadline extended</span>
to February&nbsp;4 due to server problems on the original deadline.
<hr>

<h2>Overview</h2>

<p>In this assignment you will write a naive Bayes classifier to
identify hotel reviews as either truthful or deceptive, and either
positive or negative. You will be using the word tokens as features
for classification. The homework will be graded based on the
performance of your classifiers, that is how well they perform on
unseen test data compared to the performance of a reference
classifier.

<h2>Data</h2>

The directory will have the following format:
<ul>
  <li>A top-level directory with two sub-directories, one for positive
  reviews and another for negative reviews (plus license and readme
  files which you won&rsquo;t need for the exercise).
  <li>Each of the subdirectories contains two sub-directories, one
  with truthful reviews and one with deceptive reviews.
  <li>Each of these subdirectories contains four subdirectories,
  called &ldquo;folds&rdquo;.
  <li>Each of the folds contains 80 text files with English text (one
  review per file).
</ul>

<p>The grading script will train your model on all of the training
data, and test the model on unseen data in a similar format. The
directory structure and file names of the test data will not reveal
the true labels of the individual test files.

<h2>Programs</h2>

<p>You will write two programs: <code>nblearn.py</code> will learn a
naive Bayes model from the training data, and
<code>nbclassify.py</code> will use the model to classify new data. If
using Python 3, you will name your programs <code>nblearn3.py</code>
and <code>nbclassify3.py</code>. The learning program will be invoked
in the following way:

<p><code>&gt; python nblearn.py /path/to/input</code>

<p>The argument is the directory of the training data; the program
will learn a naive Bayes model, and write the model parameters to a
file called <code>nbmodel.txt</code>. The format of the model is up to
you, but it should contain sufficient information for
<code>nbclassify.py</code> to successfully classify new data.

<p>The classification program will be invoked in the following way:

<p><code>&gt; python nbclassify.py /path/to/input</code>

<p>The argument is the directory of the test data; the program
will read the parameters of a naive Bayes model from the file
<code>nbmodel.txt</code>, classify each file in the test data, and
write the results to a text file called <code>nboutput.txt</code> in
the following format:

<p><code>label_a label_b path1<br>label_a label_b path2</code>
<br>&#x22EE;</p>

<p>In the above format, <code>label_a</code> is either
&ldquo;truthful&rdquo; or &ldquo;deceptive&rdquo;,
<code>label_b</code> is either &ldquo;positive&rdquo; or
&ldquo;negative&rdquo;, and <code>path<i>n</i></code> is the path of
the text file being classified.

<h2>Grading</h2>

<p>We will train your model, run your classifier on new test data, and
compute the F1 score of your output compared to a reference annotation
for each of the four classes (truthful, deceptive, positive, and
negative). Your grade will be the mean of the four F1 scores, scaled
to the performance of a naive Bayes classifier developed by the TAs
(so if that classifier has F1=0.8, then a score of 0.8 will receive a
grade of 100%, and a score of 0.72 will receive a grade of 90%).


<h2>Notes</h2>

<ul>
  <li><strong>Development data.</strong> While developing your
  programs, you should reserve some of the data as development data in
  order to test the performance of your programs. The submission
  script on Vocareum will use folds 2, 3, and 4 as training data, and
  fold 1 as development data: that is, it will run
  <code>nblearn.py</code> on a directory containing only folds 2, 3,
  and 4, and it will run <code>nbclassify.py</code> on a directory
  containing only fold 1. While developing on your own you may use
  different splits of the data. The grading script will use all 4
  folds for training, and unseen data for testing.
  <li><strong>Problem formulation.</strong> You may treat the problem
  as two binary classification problems (truthful/deceptive and
  positive/negative), or as a 4-class single classification
  problem. Choose whichever works better.
  <li><strong>Smoothing and unknown tokens.</strong> You should
  implement some method of smoothing for the training data and a way
  to handle unknown vocabulary in the test data, otherwise your
  programs won&rsquo;t work. The reference solution will use add-one
  smoothing on the training data, and will simply ignore unknown
  tokens in the test data. You may use more sophisticated methods
  which you implement yourselves.
  <li><strong>Tokenization.</strong> You&rsquo;d need to develop some
  reasonable method of identifying tokens in the text (since these are
  the features for the naive Bayes classifier). Some common options
  are removing certain punctuation, or lowercasing all the letters.
  You may also find it useful to ignore certain high-frequency or
  low-frequency tokens. You may use any tokenization method which you
  implement yourselves. Experiment, and choose whichever works best.
</ul>



</body>
</html>